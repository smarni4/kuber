########################### Container ######################################

# Container's are isolated environment's with their own operating system, libs, and dependencies.

# As the containers have their own OS, libs, adn dependencies it is easy for operations team to test and build the application.

# Developers will provide an docker image of application that consists of docker file and developed application to the operations team.

# Using that image, the operations team can test and set the application easily because it will run in the same manner on every OS and deploy it easily using the docker file.

########################### Container Orchestration #######################

# After building up the containers, we have to scale up/down based on the users and many containers will base on other containers or other backend services. To run the application without any 
# interruption and to solve these kind of issues, we have to orchestrate the containers by automatically deploying and managing them. This process of automatically deploying and managing them 
# is known as container orchestration.

# Kubernetes is one of the technology that performs container orchestration. There are many technologies such as docker swarm and MESOS, but there are some limitations in docker swarm and MESOS
# is hard to use.

# The advantages of container orchestration are even when your hardware is down, your application will run as it runs on multiple nodes. We can easily deploy nodes in few seconds based on the 
#  requirements.

########################### Kubernetes Architecture #######################

# ----> NODES ----> It is a machine, on which kubernetes is installed. They are defined into Master and Worker machines. Containers are launched on nodes using the kubernetes. If a node fails to run the application running on that node will goes down. To overcome this we have to deploy morethan one node.

# ----> CLUSTER --> It is a group of nodes together. If one of the node is failed, the application will run using other nodes. Due to the more number of nodes, the work load is distributed among all the nodes. 

# ----> Master Node --> As I said above, there are two kinds of nodes master and working node. Master node will manage the worker nodes and assign the load to them. If any worker node is failed, the master will assign that failed node work load to other node. It also scales up/down the node count based on the work load.
	
		    ---> Master            ----> Worker 
						
			Kube-apiserver <------> kubelet
			etcd			Container Runtime
			Controller	
			Scheduler

# ----> API server --> It is the pathway between users, management devices, Command line interfaces and kubernetes cluster.

# ----> ETCD ---> It is the key-value store used by the kubernetes to store all data used to manage the cluster. It stores all the data in every node at etcd located in the respective master node. ETCD is responsible for implementing locks within the clusters to ensure there are no conflicts between the masters.

# ----> Controller --> It is respnsible for noticing and responding when nodes, containers, and endpoints goes down. The controllers makes decisions to bring up new nodes, containers in this situation,

# ----> Scheduler ---> It is responsible for scheduling the distribution of containers across nodes.

# ----> Kubelet -----> It is the agent on every node that is responsible to make sure that every container on that node is running as expected. It interacts with the master by forwarding the worker node status to the master an takes the orders from the master to the worker node.

# ----> Container runtime ---> It is the underlying software that runs the container.( EG: DOCKER )  

######################################################################################
#########################  KUBECTL ###################################################
######################################################################################

 kubectl run hello-minkube -----> It deploy the hello-minikube appplication in the kubernetes cluster.

 kubectl cluster-info ----------> It shows the information about the cluster.

 kubectl get nodes -------------> It shows all the nodes in the cluster.

 kubectl edit pod [pod_name] ---> It opens the yaml file of pod where we can edit the file and make required changes.

 kubectl apply -f [yamlfile] ---> It creates a pod with the requirements given in that yaml file.

########################## PODS ######################################################

# PODS is the smallest thing in the kubernetes that we can create.

# In kubernetes we deploy applications in the form of containers. However, the containers are not directly deployed into the cluster they will encapsulated into the pods inside the cluster.

# If we want to scale up our application, we have to deploy more number of pods. we shouldn't add the multiple container instances inside single pod to scale up our application.

# A single pod can have multiple instances but not same type of instances. Fr instance, a pod will have a appllication instance and helper container, which will do some supporting task to run  
# the application container successfully.

# These helper container will do the work such as processing the data entered by the user, files uploaded by the user. So, this instance will get created along with the application instance and # get deleted when the application instance is deleted.

# These two instances will communicate with each other directly by reffering to each other as local host since they share the same network namespace and same storage space.

###################################################################################################
###################################################################################################

      To start a new POD --------> kubectl run [POD name] --image [image name] 

      To start the helper POD ---> kubectl run helper -link [pod name]
 
############################# YAML ################################################################

# It represents the config data of the application.

# LISTS 	DICTIONARIES 		LISTS IN DICTIONARIES

LIST NAME:	DICT NAME:		  LIST NAME:
- ITEM		   KEY: VALUE		    - DICT NAME:
- ITEM		   KEY: VALUE			      KEY: VALUE
						 KEY: VALUE
					  LIST NAME2:
					    - DICT NAME2:
                  KEY: VALUE
                  KEY: VALUE

####################### PODS WITH YAML ############################################################

# The kubernetes defination file always consists of four fields: apiVersion, kind, metadate, spec.

# apiVersion: Version of kubernetes api we are using to create the objects. 

# The apiVersion of various objects are: 
	
	POD	 	      v1
	Service  	  v1
	ReplicaSet	apps/v1
	Deployment	apps/v1

# The kind values are POD, Service, Replicaset, Deployment

# The metadata is the data about the object such as name and label.

# The spec is where we provide additional information about our application.

# The example YAML file of the POD is:

apiVersion: v1
kind: Pod
metadata:
  name: myapp-pod
  labels:
    app: myapp
    type: front-end
spec:
  containers:			            ------		
    - name: nginx-container	        |---->	  This is a dictionary with name containers consists of lists starting with name.
      image: nginx 		        ------

# After finishing the YAML file we have to run the command 
        ##### kubectl [create/apply] -f [filename.yml] ##### to create the pod.

# After creating the pod we can verify it by running the commands:

	kubectl get pods	
	
	kubectl describe pod [pod_name]

# To edit the POD info after creating the POD, we have to run the command 
        ##### kubectl edit pod [pod_name] ######

####################################################################################################################################
############################ Replica Set and Replication Controllers ###############################################################
####################################################################################################################################

####### Replication Controller ########

# The replication controller helps in maintaining the specified number of pods to stay alive inside the node to make the application run without any interruption.

# Using replication controller we can do load balancing and scaling.

# Replication controller and Replica set both have the same purpose but they are not same.

# Replication controller is older version and it is replaced with the Replica set.

# The syntax of relication controller is

apiversion: v1

kind: ReplicationController

metadata:
  name: myapp-rc
  labels:
    app: myapp
    type: front-end

spec:
  template:
    
    metadata:		--------------
      name: myapp-pod		    --
      labels:			          --
	app: myapp		            --
	type: front-end		        ---> [ metadata and spec of the pod ]
   				                  --
    spec:			              --
      containers:		        --
	- name: nginx-container   --
	  image: nginx	 -----------
  
  replicas:3

# After creating the replication controller yaml file we have to create the controller using the command 
              ### kubectl create/apply -f [filename] #####

# After creating the replication controllers we can cross check them using the command 
          ### kubectl get replicationcontroller ###

# As we mentioned the replicas: 3, the replication controller will create 3 pods automatically. If we delete one of the pod manually or it get deleted the replication controller will
# automatically create the pods untill the number of pods get equal to the replicas mentioned in the yaml file.

############## ReplicaSet ###########

# The replicaset syntax is similar to the replication controller but it has an extra variable known as selector.

# The labels and selectors in yaml file will help the replica set to identify the pods that it has to watch and create one if the number of that pods in the cluster are less than the 
# defined replicas in the replica set yaml file.

# In selector, we have to mention a key ### matchlabels ###, which matches with the labels mentioned in the template dictionary. It helps the replica set to sort out the pods that it 
# has to watch and maintain them from the remaining pods in that cluster.

# The syntax of replicaset is same as the above mentioned syntax of replication controller but the selector key should be added next to the replicas.

# --> selector:
	matchLabels:
	  type: front-end

# We also need to change the apiversion and kind to apps/v1 and ReplicaSet respectively.

######## Scale ##############33

# To get the replicasets created we have to use the command 
              ### kubectl get replicaset ###

# To delete the replicaset we have to use the command 
              ### kubectl delete replicaset [replicaset name] ###
 
# To scale the replicaset we have to edit the replicaset defination file replicas key value to required number.

# After editing it, we have to replace the file with old file using the command 
              ### kubectl replace -f [filename] ####

# We can also update the file using the command 
            ### kubectl scale --replicas=6 -f [filename] ###
						### kubectl scale --replicas=6 KIND NAME [ given in the metadata ]

# The replicas value in defination file will not get updated if we use the scale command to do so. It only update the system to scale the pods.

# To see the details of replica set we have to use the command
            ### kubectl describe replicaset [replicaset name]
   
#########################################################################################################################################################################################   




